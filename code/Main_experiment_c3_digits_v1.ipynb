{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статья, из которой заимствован метод оптимизации нейросети:\n",
    "https://arxiv.org/pdf/1704.04289.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirill/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс SimpleTwoLayerNN задает архитектуру полносвязной нейросети с одним скрытым слоем. Принимает на вход размерности входа, скрытого слоя и выхода. Поддерживает задачи классификации и регрессии.\n",
    "\n",
    "Весь функционал модели реализован в классе NNFunctional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTwoLayerNN():\n",
    "    def __init__(self, input_dim, hidden_size, output_dim, mode='regression'):\n",
    "        xavier = np.sqrt(6.0/(input_dim+hidden_size))\n",
    "        xavier2 = np.sqrt(6.0/(output_dim+hidden_size))\n",
    "        #weights matrices and vectors of the nn\n",
    "        self.hidden_weights = tf.Variable(tf.random_uniform((input_dim, hidden_size),\n",
    "                                                    minval=-xavier, maxval=xavier, dtype=tf.float64),\n",
    "                                  name='hidden_weights')\n",
    "        self.hidden_bias = tf.Variable(tf.random_uniform((hidden_size,),\n",
    "                                                         minval=-xavier, maxval=xavier, dtype=tf.float64), \n",
    "                                       name='hidden_bias')\n",
    "        self.output_weights = tf.Variable(tf.random_uniform((hidden_size, output_dim),\n",
    "                                                            minval=-xavier2, maxval=xavier2, dtype=tf.float64), \n",
    "                                          name='output_weights')\n",
    "        self.output_bias = tf.Variable(tf.random_uniform((output_dim,), minval=-xavier2, maxval=xavier2, dtype=tf.float64), \n",
    "                                       name='output_bias')\n",
    "\n",
    "        #0-1 matrices to disable/enable optimization to parameters\n",
    "        self.hidden_opt_matrix = tf.ones(self.hidden_weights.shape, dtype=tf.float64)\n",
    "        self.output_opt_matrix = tf.ones(self.output_weights.shape, dtype=tf.float64)\n",
    "\n",
    "        #creating tensors for input, target and output\n",
    "        self.X = tf.placeholder(tf.float64, [None, input_dim])\n",
    "        self.Y = tf.placeholder(tf.int32, [None, 1])\n",
    "        self.hidden_layer = tf.nn.tanh(tf.add(self.hidden_bias, tf.matmul(self.X, self.hidden_weights)))\n",
    "        if mode == 'regression':\n",
    "            self.output = tf.nn.relu(tf.add(self.output_bias, tf.matmul(self.hidden_layer, self.output_weights)))\n",
    "        if mode == 'classification':\n",
    "            self.output = tf.nn.softmax(tf.add(self.output_bias, tf.matmul(self.hidden_layer, self.output_weights)))\n",
    "        if mode == 'regression':\n",
    "            self.prediction = self.output\n",
    "        if mode == 'classification':\n",
    "            self.prediction = tf.argmax(self.output, axis=1)\n",
    "\n",
    "        #creating input, target and output of size of one to compute C\n",
    "        self.X_one = tf.placeholder(tf.float64, [1, input_dim])\n",
    "        self.Y_one = tf.placeholder(tf.int32, [1, 1])\n",
    "        self.hidden_for_one = tf.nn.tanh(tf.add(self.hidden_bias, tf.matmul(self.X_one, self.hidden_weights)))\n",
    "        if mode == 'regression':\n",
    "            self.output_for_one = tf.nn.relu(tf.add(self.output_bias, \\\n",
    "                                                    tf.matmul(self.hidden_for_one, self.output_weights)))\n",
    "        if mode == 'classification':\n",
    "            self.output_for_one = tf.nn.softmax(tf.add(self.output_bias, \\\n",
    "                                                       tf.matmul(self.hidden_for_one, self.output_weights)))\n",
    "\n",
    "        \n",
    "    def get_all_weights(self):\n",
    "        return [self.hidden_weights, self.hidden_bias, self.output_weights, self.output_bias]\n",
    "    \n",
    "    def get_opt_matrices(self):\n",
    "        return [self.hidden_opt_matrix,\n",
    "                tf.ones(self.hidden_bias.shape, dtype=tf.float64),\n",
    "                self.output_opt_matrix,\n",
    "                tf.ones(self.output_bias.shape, dtype=tf.float64)]\n",
    "    \n",
    "    def get_outputs(self):\n",
    "        return self.output, self.output_for_one\n",
    "    \n",
    "    def get_prediction(self):\n",
    "        return self.prediction\n",
    "    \n",
    "    def get_n_params(self): #returns the whole number of nn's params\n",
    "        hidden_weights_size = int(np.product(self.hidden_weights.shape))\n",
    "        hidden_bias_size = int(np.product(self.hidden_bias.shape))\n",
    "        output_weights_size = int(np.product(self.output_weights.shape))\n",
    "        output_bias_size = int(np.product(self.output_bias.shape))\n",
    "        N = hidden_weights_size + hidden_bias_size + output_weights_size + output_bias_size\n",
    "        return N\n",
    "    \n",
    "    def get_xy(self):\n",
    "        return self.X, self.X_one, self.Y, self.Y_one\n",
    "    \n",
    "    def predict(self, X, session):\n",
    "        return session.run(self.prediction, feed_dict={self.X:X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс NNFunctional принимает в качестве парамтеров инициализации нейросеть и параметры для ее обучения и оценки качества. В нем реализованы следующие методы:\n",
    "\n",
    "* fit - оптимизация параметров нейросети с данными ограничениями\n",
    "* prune(p) - зануление p*n_params весов с наименьшим абсолютным значением\n",
    "* disable_optimization(p) - отключение оптимизации для p*n_params весов с наименьшим абсолютным значением в precondition-матрице\n",
    "* reset_all_params - возврат нейросети в исходное состояние для последующего обучения \"с нуля\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class NNFunctional():\n",
    "    def __init__(self, model,\n",
    "                 loss,\n",
    "                 metric, \n",
    "                 learning_rate=1e-3,\n",
    "                 k_coef=1, # k_t = k_coef / t (see the article, page 12) \n",
    "                 batch_size=32):\n",
    "        \n",
    "        #initializing train and evaluation parameters\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.metric = metric\n",
    "        self.session = tf.Session()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.k_coef = k_coef\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #-------------------------------------------------------------------------------------------------------------\n",
    "        # creating computation graph\n",
    "        #-------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        #inputs, targets and outputs of the model, for batch and for single element\n",
    "        self.output, self.output_for_one = self.model.get_outputs()\n",
    "        self.X, self.X_one, self.Y, self.Y_one = self.model.get_xy()\n",
    "        self.model_weights = self.model.get_all_weights()\n",
    "        self.n_weights = len(self.model_weights)\n",
    "        self.train_step = tf.Variable(10, dtype=tf.float64) # starting t equals to 10 to avoid large jumps in begin\n",
    "        \n",
    "        #0-1 matrices that disable/enable optimization of a parameter, and their update operations\n",
    "        self.opt_matrices = [tf.Variable(matrix, dtype=tf.float64, trainable=False) \\\n",
    "                             for matrix in self.model.get_opt_matrices()]\n",
    "        self.opt_placeholders = [tf.placeholder(dtype=tf.float64, shape=self.opt_matrices[i].shape) \\\n",
    "                                 for i in range(self.n_weights)]\n",
    "        self.update_opt_matrices = [self.opt_matrices[i].assign(self.opt_placeholders[i]) \\\n",
    "                                    for i in range(self.n_weights)]\n",
    "        #whole number of model's parameters\n",
    "        self.N = self.model.get_n_params()\n",
    "        \n",
    "        #tensors of prediction and score of the model\n",
    "        self.prediction = self.model.get_prediction()\n",
    "        self.model_score = self.metric(self.prediction, self.Y)\n",
    "        \n",
    "        #C is the covariance matrix of gradient noise (see the article)\n",
    "        xavier = np.sqrt(6.0 / self.N)\n",
    "        self.C = [tf.Variable(tf.random_uniform(matrix.shape, minval=0, maxval=xavier, dtype=tf.float64)) \\\n",
    "                  for matrix in self.model_weights]\n",
    "        #H is the preconditioner (the article, corollary 3)\n",
    "        self.H = [2 * self.batch_size / (self.N * c) for c in self.C]\n",
    "        \n",
    "        #creating tensors for losses and gradients\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "        self.loss_function = tf.reduce_mean(self.loss(self.Y, self.output))\n",
    "        self.loss_function = tf.reduce_mean(self.loss(self.Y, self.output))\n",
    "        self.loss_for_one = tf.reduce_mean(self.loss(self.Y_one, self.output_for_one))\n",
    "        self.gradients = [x[0] for x in self.optimizer.compute_gradients(self.loss_function, \\\n",
    "                                                                          var_list=self.model_weights)]\n",
    "        self.gradients_for_one = [x[0] for x in self.optimizer.compute_gradients(self.loss_for_one, \\\n",
    "                                                                                 var_list=self.model_weights)]\n",
    "        \n",
    "        #creating update operations for weights and covariance matrix C\n",
    "        self.new_model_weights = [self.model_weights[i] - self.opt_matrices[i] * self.gradients[i] * \\\n",
    "                                  self.learning_rate * self.H[i] \\\n",
    "                            for i in range(self.n_weights)]\n",
    "        self.update_weights = [self.model_weights[i].assign(self.new_model_weights[i]) \\\n",
    "                               for i in range(self.n_weights)]\n",
    "        #online estimating C (see the article, page 12)\n",
    "        self.kt = self.k_coef / self.train_step\n",
    "        self.update_train_step = self.train_step.assign(self.train_step + 1)\n",
    "        self.new_C = [(1 - self.kt) * self.C[i] + \\\n",
    "                      self.kt * (self.gradients_for_one[i] - self.gradients[i]) ** 2 \\\n",
    "                 for i in range(self.n_weights)]\n",
    "        self.update_C = [self.C[i].assign(self.new_C[i]) for i in range(self.n_weights)]\n",
    "        \n",
    "        #tensors for changing weights in function prune\n",
    "        self.weight_placeholders = [tf.placeholder(dtype=tf.float64, \\\n",
    "                                                   shape=self.model_weights[i].shape) \\\n",
    "                                    for i in range(self.n_weights)]\n",
    "        self.change_weights = [self.model_weights[i].assign(self.weight_placeholders[i]) \\\n",
    "                               for i in range(self.n_weights)]\n",
    "        \n",
    "        #initializers\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        self.local_op = tf.local_variables_initializer()\n",
    "\n",
    "    \n",
    "    def fit(self, \n",
    "            X_train,\n",
    "            y_train,\n",
    "            steps,\n",
    "            val_data=None,\n",
    "            verbose_freq=0,\n",
    "            warm_start=False,\n",
    "            print_out=True,\n",
    "            tqdm=True):        \n",
    "        \n",
    "        if val_data is not None:\n",
    "            X_val, y_val = val_data\n",
    "        train_history = []\n",
    "        val_history = []\n",
    "        \n",
    "        #intitalizing variables\n",
    "        if not warm_start:\n",
    "            self.session.run(self.init_op)\n",
    "        self.session.run(self.local_op)\n",
    "        \n",
    "        #--------------------------------------------------------------------------------------------------------------\n",
    "        # train loop\n",
    "        #--------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        if tqdm:\n",
    "            step_numbers = tqdm_notebook(np.arange(steps))\n",
    "        else:\n",
    "            step_numbers = range(steps)\n",
    "        for i in step_numbers:\n",
    "            #creating batch and single element for the trian step\n",
    "            ids = np.random.choice(np.arange(len(X_train)), size=self.batch_size)\n",
    "            batch = X_train[ids]\n",
    "            labels = y_train[ids]\n",
    "            one_id = np.random.choice(np.arange(len(X_train)), size=1)\n",
    "            one_X = X_train[one_id]\n",
    "            one_y = y_train[one_id]\n",
    "            \n",
    "            #train step: updating parameters\n",
    "            inputs = {self.X:batch, self.Y:labels, self.X_one:one_X, self.Y_one:one_y}\n",
    "            self.session.run(self.update_C, feed_dict=inputs)\n",
    "            if i == 0:\n",
    "                continue\n",
    "            self.session.run(self.update_weights, feed_dict=inputs)\n",
    "            self.session.run(self.update_train_step)\n",
    "            \n",
    "            #showing and saving current model score on train and validation\n",
    "            if i % verbose_freq == 0 and verbose_freq > 0:\n",
    "                self.session.run(self.local_op)\n",
    "                train_score = self.session.run(self.model_score, feed_dict={self.X:X_train, self.Y:y_train})\n",
    "                train_history.append(train_score)\n",
    "                if val_data is not None:\n",
    "                    val_score = self.session.run(self.model_score, feed_dict={self.X:X_val, self.Y:y_val})\n",
    "                    val_history.append(val_score)\n",
    "\n",
    "                if print_out:\n",
    "                    #print(self.session.run(self.C))\n",
    "                    print('step number', i)\n",
    "                    print('train score', train_score)\n",
    "                    print('validation score', val_score)\n",
    "        return train_history, val_history\n",
    "        \n",
    "    def prune(self, p, mode='minimal'):\n",
    "        #getting current weights and values of optimization matrices\n",
    "        weights = self.session.run(self.model_weights)\n",
    "        opt_matrices = self.session.run(self.opt_matrices)\n",
    "        new_weights = []\n",
    "        new_opt = []\n",
    "        \n",
    "        #set p*N weights with lowest absolute value to zero, and set their optimization coefs to zero\n",
    "        for matrix, opt_matrix in zip(weights, opt_matrices):\n",
    "            weight_vector = matrix.ravel()\n",
    "            opt_vector = opt_matrix.ravel()\n",
    "            n_params_to_cut = int(weight_vector.shape[0] * p)\n",
    "            if mode == 'minimal':\n",
    "                argsort = np.argsort(np.abs(weight_vector))\n",
    "                params_to_cut = argsort[:n_params_to_cut]\n",
    "            if mode == 'random':\n",
    "                params_to_cut = np.random.choice(np.arange(len(weight_vector)), n_params_to_cut, replace=False)\n",
    "            weight_vector[params_to_cut] = 0\n",
    "            opt_vector[params_to_cut] = 0\n",
    "            new_weights.append(weight_vector.reshape(matrix.shape))\n",
    "            new_opt.append(opt_vector.reshape(opt_matrix.shape))\n",
    "            \n",
    "        #updating tensors of weights and optimization matrices\n",
    "        self.session.run(self.local_op)\n",
    "        for i in range(self.n_weights):\n",
    "            self.session.run(self.change_weights[i], feed_dict={self.weight_placeholders[i]:new_weights[i]})\n",
    "            self.session.run(self.update_opt_matrices[i], feed_dict={self.opt_placeholders[i]:new_opt[i]})\n",
    "        self.session.run(self.local_op)\n",
    "    \n",
    "    def disable_optimization(self, p, mode='H'):\n",
    "        opt_matrices = self.session.run(self.opt_matrices)\n",
    "        C = self.session.run(self.C)\n",
    "        gradients = self.session.run(self.gradients, feed_dict={self.X:X_train, self.Y:y_train})\n",
    "        H = [1 / c for c in C] #really, H is proportional to 1/C\n",
    "        new_opt = []\n",
    "        \n",
    "        # setting optimization coefs of p*N params to zero\n",
    "        for matrix, gradient, opt_matrix in zip(H, gradients, opt_matrices):\n",
    "            H_vector = matrix.ravel()\n",
    "            grad_vector = gradient.ravel()\n",
    "            opt_vector = opt_matrix.ravel()\n",
    "            n_params_to_disable = int(H_vector.shape[0] * p)\n",
    "            # disable optimization for params with fewest absolute preconditioner value\n",
    "            if mode == 'H':\n",
    "                argsort = np.argsort(np.abs(H_vector * grad_vector))\n",
    "                params_to_disable = argsort[:n_params_to_disable]\n",
    "            # disable optimization for p*N randomly chosen params\n",
    "            if mode == 'random':\n",
    "                params_to_disable = np.random.choice(np.arange(len(H_vector)), n_params_to_disable, replace=False)\n",
    "            # disable optimization for params with fewest absolute gradient value\n",
    "            if mode == 'minimal':\n",
    "                argsort = np.argsort(np.abs(grad_vector))\n",
    "                params_to_disable = argsort[:n_params_to_disable]\n",
    "            opt_vector[params_to_disable] = 0\n",
    "            new_opt.append(opt_vector.reshape(opt_matrix.shape))\n",
    "            \n",
    "        #running the changes\n",
    "        for i in range(self.n_weights):\n",
    "            self.session.run(self.update_opt_matrices[i], feed_dict={self.opt_placeholders[i]:new_opt[i]})\n",
    "            \n",
    "    def reset_all_params(self):\n",
    "        #setting all the parameters of the model to the initial state\n",
    "        self.session.run(self.init_op)\n",
    "        self.session.run(self.local_op)\n",
    "        self.session.run(self.model_weights)\n",
    "        for i in range(self.n_weights):\n",
    "            self.opt_matrices[i] = tf.ones(self.opt_matrices[i].shape, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем вычислительный эксперимент на датасете digits (классификация рукописных цифр, 64 признака, 10 классов).\n",
    "\n",
    "В качестве функции потерь возьмем кроссэнтропию, метрику качества - accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kirill/anaconda3/envs/tf_cpu/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=42, test_size=0.3)\n",
    "y_train = y_train[:, np.newaxis]\n",
    "y_test = y_test[:, np.newaxis]\n",
    "X_mean = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "eps = 1e-8\n",
    "X_train = (X_train - X_mean) / (X_std + eps)\n",
    "X_test = (X_test - X_mean) / (X_std + eps)\n",
    "X_train = X_train[:, X_std > 0]\n",
    "X_test = X_test[:, X_std > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = SimpleTwoLayerNN(X_train.shape[1], 32, 10, mode='classification')\n",
    "func = NNFunctional(model=nn, \n",
    "                    loss=tf.losses.sparse_softmax_cross_entropy, \n",
    "                    metric=lambda x, y:tf.metrics.accuracy(x, y)[1],\n",
    "                    learning_rate=0.01,\n",
    "                    k_coef=1,\n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разных значений р проведем 1000 шагов полной оптимизации, затем занулим p*N весов и проведем еще 4000 шагов оптимизации остальных весов. Построим график качества модели в зависимости от р"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0f4fa8e2ae4b3fa85bcc6d5bc33884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prune_params = np.linspace(0, 1, 51)[:-1]\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for p in tqdm_notebook(prune_params):\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for _ in range(5):\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=200,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=199,\n",
    "                                             warm_start=False,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.prune(p)\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=3000,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=2999,\n",
    "                                             warm_start=True,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.reset_all_params()\n",
    "        train_acc.append(train_history[-1])\n",
    "        val_acc.append(val_history[-1])\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs = np.array(train_accs)\n",
    "val_accs = np.array(val_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./results/prune_train_acc.txt', train_accs)\n",
    "np.savetxt('./results/prune_val_acc.txt', val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разных значений р проведем 1000 шагов полной оптимизации, затем отключим оптимизацию для p*N параметров и проведем еще 4000 шагов оптимизации остальных весов. Построим график качества модели в зависимости от р"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ca3d6727af4338ad9b00ab0181592c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "disable_params = np.linspace(0, 1, 51)\n",
    "train_accs_disable = []\n",
    "val_accs_disable = []\n",
    "for p in tqdm_notebook(disable_params):\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for _ in range(5):\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=200,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=199,\n",
    "                                             warm_start=False,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.disable_optimization(p, mode='H')\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=3000,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=2999,\n",
    "                                             warm_start=True,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.reset_all_params()\n",
    "        train_acc.append(train_history[-1])\n",
    "        val_acc.append(val_history[-1])\n",
    "    train_accs_disable.append(train_acc)\n",
    "    val_accs_disable.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 5) (51, 5)\n"
     ]
    }
   ],
   "source": [
    "train_accs_disable = np.array(train_accs_disable)\n",
    "val_accs_disable = np.array(val_accs_disable)\n",
    "print(train_accs_disable.shape, val_accs_disable.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./disable_train_acc.txt', train_accs_disable)\n",
    "np.savetxt('./disable_val_acc.txt', val_accs_disable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable optimization (minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1a79945efe438c96dca06e34a69384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "disable_params = np.linspace(0, 1, 51)\n",
    "train_accs_disable_base = []\n",
    "val_accs_disable_base = []\n",
    "for p in tqdm_notebook(disable_params):\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for _ in range(5):\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=200,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=199,\n",
    "                                             warm_start=False,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.disable_optimization(p, mode='minimal')\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=3000,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=2999,\n",
    "                                             warm_start=True,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.reset_all_params()\n",
    "        train_acc.append(train_history[-1])\n",
    "        val_acc.append(val_history[-1])\n",
    "    train_accs_disable_base.append(train_acc)\n",
    "    val_accs_disable_base.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs_disable_base = np.array(train_accs_disable_base)\n",
    "val_accs_disable_base = np.array(val_accs_disable_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./results/disable_train_acc_base.txt', train_accs_disable_base)\n",
    "np.savetxt('./results/disable_val_acc_base.txt', val_accs_disable_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный выбор параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disable optmization (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61844daeeb7e4e4c80dd6313d04837df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=51), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "disable_params = np.linspace(0, 1, 51)\n",
    "train_accs_disable_random = []\n",
    "val_accs_disable_random = []\n",
    "for p in tqdm_notebook(disable_params):\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for _ in range(5):\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=200,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=199,\n",
    "                                             warm_start=False,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.disable_optimization(p, mode='random')\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=3000,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=2999,\n",
    "                                             warm_start=True,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.reset_all_params()\n",
    "        train_acc.append(train_history[-1])\n",
    "        val_acc.append(val_history[-1])\n",
    "    train_accs_disable_random.append(train_acc)\n",
    "    val_accs_disable_random.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs_disable_random = np.array(train_accs_disable_random)\n",
    "val_accs_disable_random = np.array(val_accs_disable_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./results/disable_train_acc_random.txt', train_accs_disable_random)\n",
    "np.savetxt('./results/disable_val_acc_random.txt', val_accs_disable_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067ce3fae1184e03bc8e52ef593372f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prune_params = np.linspace(0, 1, 51)[:-1]\n",
    "train_accs_prune_random = []\n",
    "val_accs_prune_random = []\n",
    "for p in tqdm_notebook(prune_params):\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    for _ in range(5):\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=200,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=199,\n",
    "                                             warm_start=False,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.prune(p, mode='random')\n",
    "        train_history, val_history = func.fit(X_train,\n",
    "                                             y_train,\n",
    "                                             steps=3000,\n",
    "                                             val_data=(X_test, y_test),\n",
    "                                             verbose_freq=2999,\n",
    "                                             warm_start=True,\n",
    "                                             print_out=False,\n",
    "                                             tqdm=False\n",
    "                                            )\n",
    "        func.reset_all_params()\n",
    "        train_acc.append(train_history[-1])\n",
    "        val_acc.append(val_history[-1])\n",
    "    train_accs_prune_random.append(train_acc)\n",
    "    val_accs_prune_random.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accs_prune_random = np.array(train_accs_prune_random)\n",
    "val_accs_prune_random = np.array(val_accs_prune_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./results/prune_train_acc_random.txt', train_accs_prune_random)\n",
    "np.savetxt('./results/prune_val_acc_random.txt', val_accs_prune_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (CPU)",
   "language": "python",
   "name": "tensorflow-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
